{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.pathlabelchannel import get_path_label_channel_by_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.sampling import generate_batched_samples_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.cnnReduce import train_cnn_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnmodel(i : int):\n",
    "    drop = 51\n",
    "    remainingChannels = [\n",
    "    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, \n",
    "    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, \n",
    "    32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, \n",
    "    47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61\n",
    "    ]\n",
    "\n",
    "    dropIndex = [drop, remainingChannels[i]]\n",
    "    print(dropIndex)\n",
    "\n",
    "    path, label, channel = get_path_label_channel_by_index(0)\n",
    "\n",
    "    sample, hotkey = generate_batched_samples_from_directory(path, label, channel, dropIndex)\n",
    "    print(np.shape(sample), np.shape(hotkey))\n",
    "\n",
    "    model = train_cnn_reduce(sample, hotkey, 60, 0.80, 32, 60)\n",
    "\n",
    "    del dropIndex, sample, hotkey, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 0]\n",
      "['13_20151115.mat', '10_20151014.mat', '8_20151103.mat', '11_20150916.mat', '5_20160406.mat', '12_20150725.mat', '9_20151028.mat', '7_20150715.mat', '6_20150507.mat', '15_20150508.mat', '2_20150915.mat', '3_20150919.mat', '1_20160518.mat', '14_20151205.mat', '4_20151111.mat']\n",
      "13_20151115.mat\n",
      "10_20151014.mat\n",
      "8_20151103.mat\n",
      "11_20150916.mat\n",
      "5_20160406.mat\n",
      "12_20150725.mat\n",
      "9_20151028.mat\n",
      "7_20150715.mat\n",
      "6_20150507.mat\n",
      "15_20150508.mat\n",
      "2_20150915.mat\n",
      "3_20150919.mat\n",
      "1_20160518.mat\n",
      "14_20151205.mat\n",
      "4_20151111.mat\n",
      "(677, 60, 1000) (677, 4)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 60, 1000, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 60, 200, 16)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 60, 200, 16)      64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 60, 200, 32)       4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 60, 66, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 60, 66, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 66, 48)        13872     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 60, 22, 48)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 60, 22, 48)       192       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 60, 22, 64)        27712     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 60, 7, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 60, 7, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 60, 7, 80)         46160     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 60, 2, 80)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 60, 2, 80)        320       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                614464    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 708,228\n",
      "Trainable params: 707,748\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "17/17 [==============================] - 15s 809ms/step - loss: 2.1792 - accuracy: 0.3087 - val_loss: 3.9627 - val_accuracy: 0.2868\n",
      "Epoch 2/60\n",
      "17/17 [==============================] - 13s 793ms/step - loss: 1.3962 - accuracy: 0.4122 - val_loss: 1.6871 - val_accuracy: 0.3088\n",
      "Epoch 3/60\n",
      "17/17 [==============================] - 13s 793ms/step - loss: 1.1433 - accuracy: 0.5379 - val_loss: 1.5274 - val_accuracy: 0.3529\n",
      "Epoch 4/60\n",
      "17/17 [==============================] - 13s 792ms/step - loss: 0.9802 - accuracy: 0.6192 - val_loss: 1.5339 - val_accuracy: 0.3603\n",
      "Epoch 5/60\n",
      "17/17 [==============================] - 13s 790ms/step - loss: 0.8617 - accuracy: 0.6636 - val_loss: 1.4530 - val_accuracy: 0.4265\n",
      "Epoch 6/60\n",
      "17/17 [==============================] - 13s 793ms/step - loss: 0.7159 - accuracy: 0.7597 - val_loss: 1.3680 - val_accuracy: 0.5368\n",
      "Epoch 7/60\n",
      "17/17 [==============================] - 13s 793ms/step - loss: 0.6282 - accuracy: 0.7967 - val_loss: 1.4799 - val_accuracy: 0.4853\n",
      "Epoch 8/60\n",
      "17/17 [==============================] - 13s 794ms/step - loss: 0.5225 - accuracy: 0.8558 - val_loss: 1.2554 - val_accuracy: 0.5441\n",
      "Epoch 9/60\n",
      "17/17 [==============================] - 14s 819ms/step - loss: 0.3996 - accuracy: 0.9002 - val_loss: 1.2461 - val_accuracy: 0.5809\n",
      "Epoch 10/60\n",
      "17/17 [==============================] - 14s 830ms/step - loss: 0.3362 - accuracy: 0.9224 - val_loss: 1.1740 - val_accuracy: 0.6324\n",
      "Epoch 11/60\n",
      "17/17 [==============================] - 14s 798ms/step - loss: 0.3333 - accuracy: 0.9242 - val_loss: 1.2386 - val_accuracy: 0.6176\n",
      "Epoch 12/60\n",
      "17/17 [==============================] - 14s 809ms/step - loss: 0.3157 - accuracy: 0.9372 - val_loss: 1.1757 - val_accuracy: 0.7059\n",
      "Epoch 13/60\n",
      "17/17 [==============================] - 14s 841ms/step - loss: 0.2721 - accuracy: 0.9575 - val_loss: 1.2559 - val_accuracy: 0.6250\n",
      "Epoch 14/60\n",
      " 9/17 [==============>...............] - ETA: 6s - loss: 0.2131 - accuracy: 0.9861"
     ]
    }
   ],
   "source": [
    "cnnmodel(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "415745b1e1d61104d3af98982f98eef78a31cb72b578a8185dcea89b918bc627"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
